{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from pybit.unified_trading import HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = True\n",
    "if test:\n",
    "    api_key = \"z4y2nnrknpHgvEPRtp\"\n",
    "    api_secret = \"tZlx7133h1S0uTpQUfj75W5NVIKPzqaX0yuB\"\n",
    "else:\n",
    "    api_key = \"dBlgdc5AZ29fInzDGE\"\n",
    "    api_secret = \"PMcu1fTICd5jAauLnJEU4biPCKx6PTYeuxxg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = HTTP(api_key=api_key, api_secret=api_secret, testnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_new_data(symbol: str, start_time: dt.datetime) -> pd.DataFrame:\n",
    "    resp = session.get_kline(\n",
    "        category='linear',\n",
    "        symbol=symbol,\n",
    "        interval=15,\n",
    "        start=int(start_time.timestamp() * 1000)\n",
    "    ).get('result', {})\n",
    "    data = resp.get('list', [])\n",
    "    df = pd.DataFrame(data, columns=['timestamp','open','high','low','close','volume','turnover'])\n",
    "    if df.empty:\n",
    "        return df\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    return df.set_index('timestamp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_updated(directory: str = \"data\") -> None:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    suffix = \".csv\"\n",
    "    files = [f for f in os.listdir(directory) if f.endswith(suffix)]\n",
    "    symbols = sorted({f.split(\"_\")[0] for f in files})\n",
    "\n",
    "    for idx, symbol in enumerate(symbols, 1):\n",
    "        print(f\"\\n=== [{idx}/{len(symbols)}] symbol: {symbol} ===\")\n",
    "        symbol_files = [\n",
    "            os.path.join(directory, f)\n",
    "            for f in files\n",
    "            if f.startswith(symbol + \"_\") and f.endswith(suffix)\n",
    "        ]\n",
    "        print(\"found files:\", symbol_files)\n",
    "\n",
    "        # read & merge existing\n",
    "        dfs = []\n",
    "        for fp in symbol_files:\n",
    "            df = pd.read_csv(fp, parse_dates=['timestamp']).set_index('timestamp')\n",
    "            dfs.append(df)\n",
    "        if dfs:\n",
    "            merged = pd.concat(dfs).sort_index()\n",
    "            merged = merged[~merged.index.duplicated(keep='first')]\n",
    "            latest_time = merged.index.max()\n",
    "        else:\n",
    "            merged = pd.DataFrame()\n",
    "            latest_time = None\n",
    "        print(\"merged rows:\", len(merged), \"latest_time:\", latest_time)\n",
    "\n",
    "        # fetch new\n",
    "        if latest_time is not None:\n",
    "            new = fetch_new_data(symbol, latest_time - dt.timedelta(minutes=1))\n",
    "        else:\n",
    "            new = fetch_new_data(symbol, dt.datetime.now() - dt.timedelta(days=100))\n",
    "        if new.empty:\n",
    "            print(\"no new data fetched\")\n",
    "        else:\n",
    "            print(\"new data from\", new.index.min(), \"to\", new.index.max(), \"rows:\", len(new))\n",
    "\n",
    "            combined = pd.concat([merged, new]).sort_index()\n",
    "            combined = combined[~combined.index.duplicated(keep='first')]\n",
    "            print(\"after combine rows:\", len(combined))\n",
    "            merged = combined\n",
    "\n",
    "        # save\n",
    "        full_path = os.path.join(directory, f\"{symbol}_15m_full.csv\")\n",
    "        merged.to_csv(full_path)\n",
    "        print(\"saved to:\", full_path)\n",
    "\n",
    "        # cleanup\n",
    "        for fp in symbol_files:\n",
    "            if fp != full_path:\n",
    "                os.remove(fp)\n",
    "        print(\"old files removed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [1/70] symbol: BTCUSDT ===\n",
      "found files: ['data\\\\BTCUSDT_15m_full.csv']\n",
      "merged rows: 97231 latest_time: 2025-04-21 19:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GameReaper\\AppData\\Local\\Temp\\ipykernel_6492\\2482376369.py:12: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new data from 2025-04-21 19:30:00 to 2025-04-23 16:15:00 rows: 180\n",
      "after combine rows: 97410\n",
      "saved to: data\\BTCUSDT_15m_full.csv\n",
      "old files removed\n",
      "\n",
      "=== [2/70] symbol: LTCUSDT ===\n",
      "found files: ['data\\\\LTCUSDT_15m_full.csv']\n",
      "merged rows: 97231 latest_time: 2025-04-21 19:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GameReaper\\AppData\\Local\\Temp\\ipykernel_6492\\2482376369.py:12: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new data from 2025-04-21 19:30:00 to 2025-04-23 16:15:00 rows: 180\n",
      "after combine rows: 97410\n",
      "saved to: data\\LTCUSDT_15m_full.csv\n",
      "old files removed\n",
      "\n",
      "=== [3/70] symbol: LUNA2USDT ===\n",
      "found files: ['data\\\\LUNA2USDT_15m_full.csv']\n",
      "merged rows: 97231 latest_time: 2025-04-21 19:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GameReaper\\AppData\\Local\\Temp\\ipykernel_6492\\2482376369.py:12: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new data from 2025-04-21 19:30:00 to 2025-04-23 16:15:00 rows: 180\n",
      "after combine rows: 97410\n",
      "saved to: data\\LUNA2USDT_15m_full.csv\n",
      "old files removed\n",
      "\n",
      "=== [4/70] symbol: MAGICUSDT ===\n",
      "found files: ['data\\\\MAGICUSDT_15m_full.csv']\n",
      "merged rows: 82612 latest_time: 2025-04-21 19:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GameReaper\\AppData\\Local\\Temp\\ipykernel_6492\\2482376369.py:12: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new data from 2025-04-21 19:30:00 to 2025-04-23 16:15:00 rows: 180\n",
      "after combine rows: 82791\n",
      "saved to: data\\MAGICUSDT_15m_full.csv\n",
      "old files removed\n",
      "\n",
      "=== [5/70] symbol: MANAUSDT ===\n",
      "found files: ['data\\\\MANAUSDT_15m_full.csv']\n",
      "merged rows: 97231 latest_time: 2025-04-21 19:30:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GameReaper\\AppData\\Local\\Temp\\ipykernel_6492\\2482376369.py:12: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new data from 2025-04-21 19:30:00 to 2025-04-23 16:15:00 rows: 180\n",
      "after combine rows: 97410\n",
      "saved to: data\\MANAUSDT_15m_full.csv\n",
      "old files removed\n",
      "\n",
      "=== [6/70] symbol: MASKUSDT ===\n",
      "found files: ['data\\\\MASKUSDT_15m_full.csv']\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mData_updated\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 19\u001b[0m, in \u001b[0;36mData_updated\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     17\u001b[0m dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fp \u001b[38;5;129;01min\u001b[39;00m symbol_files:\n\u001b[1;32m---> 19\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dfs:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "Data_updated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [8, 61, 3, 1586, 5, 13, 1, 1, 85, 6, 13, 34, 8, 63, 1]\n",
      "Average: 125.86666666666666\n",
      "Median: 8\n",
      "Standard Deviation: 391.09843034998516\n",
      "Squared Numbers: [64, 3721, 9, 2515396, 25, 169, 1, 1, 7225, 36, 169, 1156, 64, 3969, 1]\n",
      "Results exported to results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_valid_input():\n",
    "    \"\"\"Loop until the user provides a valid list of integers.\"\"\"\n",
    "    while True:\n",
    "        text = input(\"Enter a list of integers separated by commas: \")\n",
    "        numbers = convert_to_int(text)\n",
    "        if numbers:\n",
    "            return numbers\n",
    "        print(\"Invalid input. Please enter only integers separated by commas.\")\n",
    "\n",
    "\n",
    "def convert_to_int(text):\n",
    "    \"\"\"Convert comma-separated string to list of integers.\n",
    "    Returns None if conversion fails.\"\"\"\n",
    "    try:\n",
    "        return [int(x.strip()) for x in text.split(\",\")]\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def calculate_average(arr):\n",
    "    \"\"\"Calculate the average of a list of numbers.\"\"\"\n",
    "    return sum(arr) / len(arr)\n",
    "\n",
    "\n",
    "def calculate_median(arr):\n",
    "    \"\"\"Calculate the median of a list of numbers.\"\"\"\n",
    "    sorted_arr = sorted(arr)\n",
    "    n = len(sorted_arr)\n",
    "    mid = n // 2\n",
    "    return (sorted_arr[mid - 1] + sorted_arr[mid]) / 2 if n % 2 == 0 else sorted_arr[mid]\n",
    "\n",
    "\n",
    "def calculate_std_deviation(arr):\n",
    "    \"\"\"Calculate the standard deviation of a list of numbers.\"\"\"\n",
    "    mean = calculate_average(arr)\n",
    "    variance = sum((x - mean) ** 2 for x in arr) / len(arr)\n",
    "    return variance ** 0.5\n",
    "\n",
    "\n",
    "def square_numbers(arr):\n",
    "    \"\"\"Return a list with the square of each number using a loop.\"\"\"\n",
    "    result = []\n",
    "    for x in arr:\n",
    "        result.append(x ** 2)\n",
    "    return result\n",
    "\n",
    "\n",
    "def export_to_excel(data_dict, filename=\"results.xlsx\"):\n",
    "    \"\"\"Export the results to an Excel file using pandas.\"\"\"\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    df.to_excel(filename, index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    numbers = get_valid_input()\n",
    "    avg = calculate_average(numbers)\n",
    "    med = calculate_median(numbers)\n",
    "    std = calculate_std_deviation(numbers)\n",
    "    squared = square_numbers(numbers)\n",
    "\n",
    "    print(\"Input:\", numbers)\n",
    "    print(\"Average:\", avg)\n",
    "    print(\"Median:\", med)\n",
    "    print(\"Standard Deviation:\", std)\n",
    "    print(\"Squared Numbers:\", squared)\n",
    "\n",
    "    data = {\n",
    "    \"Input\": numbers + [\"Average\", \"Median\", \"Standard Deviation\"],\n",
    "    \"Squared Numbers\": square_numbers(numbers) + [None, None, None],\n",
    "    \"Average\": [None] * len(numbers) + [avg, None, None],\n",
    "    \"Median\": [None] * len(numbers) + [None, med, None],\n",
    "    \"Standard Deviation\": [None] * len(numbers) + [None, None, std]\n",
    "    }\n",
    "\n",
    "\n",
    "    export_to_excel(data)\n",
    "    print(\"Results exported to results.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
